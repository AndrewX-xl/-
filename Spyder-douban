{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.193 Safari/537.36'\n",
    "}\n",
    "def request_douban(url, numRetries=2):\n",
    "    try:\n",
    "        response = requests.get(url=url,headers=headers)  #request.get()获取网页源代码\n",
    "        html = response.text\n",
    "        if response.status_code >= 400:\n",
    "            print('request_douban error:', response.text)\n",
    "            html = None\n",
    "            if numRetries and 500 <= response.status_code < 600:\n",
    "                # recursively retry 5xx HTTP errors\n",
    "                return request_douban(url, numRetries - 1)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('request_douban error:', e)\n",
    "        html = None\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [i for i in range(1,251)]\n",
    "names=[]\n",
    "authors=[]\n",
    "years=[]\n",
    "stars=[]\n",
    "types = []\n",
    "countries = []\n",
    "judge_peoples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_a_herf(html_whole):\n",
    "    soup_whole = BeautifulSoup(html_whole, 'html.parser')\n",
    "    html_tmp = soup_whole.find_all('div',{'class':'hd'})\n",
    "    html_tmp_info = soup_whole.find_all('div',{'class':'info'})\n",
    "    #解析电影国家\n",
    "    for tag in html_tmp_info:\n",
    "        mark = tag.find('p',{'class':''}).get_text().strip().split('/')\n",
    "        countries.append(mark[len(mark)-2].strip())\n",
    "    for tag in html_tmp:\n",
    "        herf_temp = tag.find('a')['href']\n",
    "        html_content = request_douban(herf_temp)\n",
    "        each_info(html_content)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_info(html_content):\n",
    "    soup_content = BeautifulSoup(html_content,'html.parser')\n",
    "    #解析导演\n",
    "    author_temp = soup_content.find('a',{'rel':'v:directedBy'}).get_text()\n",
    "    authors.append(author_temp)\n",
    "    #解析电影名称\n",
    "    name_temp = soup_content.find('span',{'property':'v:itemreviewed'}).get_text()\n",
    "    names.append(name_temp)\n",
    "    #解析年份\n",
    "    year_temp = soup_content.find('span',{'class':'year'}).get_text().strip('(').strip(')')\n",
    "    years.append(year_temp)\n",
    "    #解析评分\n",
    "    star_temp = soup_content.find('strong',{'property':'v:average'}).get_text()\n",
    "    stars.append((float)(star_temp))\n",
    "    #解析电影类型\n",
    "    type_temp = soup_content.find_all('span',{'property':'genre'})\n",
    "    contents=''\n",
    "    for mark in type_temp:\n",
    "        contents = contents + str(mark.get_text()) + \"/\"\n",
    "    types.append(contents.strip('/'))\n",
    "    #解析点评人数\n",
    "    judge_people_temp = soup_content.find('span',{'property':'v:votes'}).get_text()\n",
    "    judge_peoples.append((int)(judge_people_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,10):\n",
    "        url = \"https://movie.douban.com/top250?start=\"+str(i*25)\n",
    "        html = request_douban(url)\n",
    "        find_a_herf(html)\n",
    "        print(f\"第{i+1}页数据爬取成功！\")\n",
    "        time.sleep(5)"
   ]
  },
